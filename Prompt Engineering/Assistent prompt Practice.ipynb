{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52d250c8-14a6-48eb-9f1b-7569e2de753b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT full_name, salary\n",
    "FROM employees\n",
    "WHERE YEAR(join_date) = 2021\n",
    "ORDER BY salary DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "690b3bc0-b991-4e98-830f-a9e67aab5978",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT CONCAT(first_name, ' ', last_name) AS full_name, salary\n",
    "FROM employees\n",
    "WHERE YEAR(hire_date) = 2021\n",
    "ORDER BY salary DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aebccaf-74f6-4912-bc1b-e30b47595480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "describe extended employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05ad5268-2046-4c9d-b5f3-27f68fe66279",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/Workspace/Users/johrinaina80@gmail.com/dataX/Python Module/output.csv\"\n",
    ")\n",
    "\n",
    "if not df.empty:\n",
    "    spark_df = spark.createDataFrame(df)\n",
    "    distinct_cities = spark_df.select(\"city\").distinct()\n",
    "    display(distinct_cities)\n",
    "else:\n",
    "    print(\"The CSV file is empty. No data to process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb6dbec7-c166-469f-9da3-82ab8390b733",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year\n",
    "\n",
    "employees_df = spark.table(\"employees\")\n",
    "filtered_df = employees_df.filter(year(employees_df.join_date) == 2021)\n",
    "result_df = filtered_df.select(\"full_name\", \"salary\").orderBy(\"salary\", ascending=False)\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7f5b7af-419b-49e8-b375-72c2647a3115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install pandasai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9abbc2-6cd6-454d-99d0-2330a4594e45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pandasai.core import SmartDataFrame\n",
    "from pandasai.llm.fake import FakeLLM\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"name\": [\"Ram\", \"Priya\", \"Ravi\"],\n",
    "        \"salary\": [72000, 65000, 80000],\n",
    "        \"department\": [\"IT\", \"HR\", \"Finance\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "llm = FakeLLM()\n",
    "pandas_ai = PandasAI(llm)\n",
    "response = pandas_ai.run(\n",
    "    df,\n",
    "    prompt=\"Show average salary per department\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d34ace7-8913-4f5b-a246-3449664278ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eab4d626-7ee5-46dc-bf61-4ec151931b84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.utilities import SQLDatabase\n",
    "from pandasai.llm.fake import FakeLLM #Trick: reuse FakeLLM as dummy LLM\n",
    "\n",
    "#Setup dummy database (eg. SQLite)\n",
    "db = SQLDatabase.from_uri(\"sqlite:///my_demo.db\")\n",
    "\n",
    "#Use Fale LLM(simulated Ai)\n",
    "llm = FakeLLM()\n",
    "db_chain = SQLDatabaseChain.from_llm(llm, db, verbose = True)\n",
    "\n",
    "#Ask a question (will retun dummy SQL)\n",
    "result = db_chain.run(\"What is the average salary per department?\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5028335219857179,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Assistent prompt Practice",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
